<?xml version="1.0" encoding="UTF-8"?>

<section xml:id="sec-basis" xmlns:xi="http://www.w3.org/2001/XInclude">
  <title>Basis of a Vector Space</title>
  <introduction>
    <p>
      We have previously examined when a set of vectors spans a vector space. In this section, we will learn how to work with the most efficient spanning set possible.
    </p>
  </introduction>

<subsection xml:id="subsec-intro-basis">
  <title>The Definition of a Basis</title>
  
  <p>
    We begin with the notion of finite- and infinite-dimensional vector spaces.
  </p>

<definition xml:id="def-finite-dimensional">
  <statement>
    <p>
      A vector space <m>V</m> is <term>finite-dimensional</term> if there is a finite set of vectors that spans <m>V</m>. A vector space is <term>infinite-dimensional</term> if it is not finite-dimensional.
    </p>
  </statement>
</definition>

<p>
  We recall that <em>linear independence</em> in <xref ref="sec-lin-ind"/> was introduced as a way to eliminate redundancy. We pick up on this idea in the next definition.
</p>

<definition xml:id="def-basis">
  <statement>
    <p>
      Let <m>V</m> be a finite-dimensional vector space. Then a set <m>B = \{\bfv_1, \ldots, \bfv_n \}</m> is a <term>basis</term> for <m>V</m> if <m>B</m> is a linearly independent set and if <m>V = \spn\{\bfv_1,\ldots, \bfv_n\}</m>. 
    </p>
  </statement>
</definition>

<note>
  <p>
    The notion of a basis exists for infinite-dimensional vector spaces, but since the overwhelming majority of our work will be with finite-dimensional spaces, we have only given the definition in that setting.
  </p>
</note>

<example>
  <statement>
    <p>
      We recall that <m>\bfe_i</m> is the vector in <m>\ff^n</m> with <m>1</m> in the <m>i</m>th coordinate and zeros elsewhere. Then the set <m>E = \{\bfe_1, \ldots, \bfe_n\}</m> is a basis for <m>\ff^n</m>. If we form the <m>n\times n</m> matrix with these vectors as columns, we see that it is the <m>n\times n</m> identity matrix. Since there is a pivot in every column, <m>E</m> is linearly independent according to <xref ref="alg-linear-independence"/>. Then <xref ref="cor-n-vect-in-f-n"/> tells us that <m>E</m> also spans <m>\ff^n</m>. This proves that <m>E</m> is a basis for <m>\ff^n</m>. 
    </p>
    <p>
      We call this basis the <term>standard basis</term> for <m>\ff^n</m>. 
    </p>
  </statement>
</example>

<example>
  <statement>
    <p>
      We now consider the subset <m>B = \{1, t, t^2\}</m> of the vector space <m>P_2</m>. Since any vector in <m>P_2</m> can be written as <m>a(1)+b(t)+c(t^2)</m>, it is clear that <m>B</m> spans <m>P_2</m>. It is also true that <m>B</m> is linearly independent: the set <m>\{1, t\}</m> is linearly independent since neither vector is a scalar multiple of the other. And then since <m>t^2</m> is not a linear combination of <m>1</m> and <m>t</m>, we conclude that <m>B</m> is linearly independent by (the contrapositive of) the Linear Dependence Lemma (<xref ref="thm-lin-dep-lemma"/>). This proves that <m>B</m> is a basis for <m>P_2</m>. 
    </p>
    <p>
      The analogous basis for <m>P_n</m>, <m>\{1, t, \ldots, t^n \}</m>, is often called the <term>standard basis</term> for <m>P_n</m>. 
    </p>
  </statement>
</example>

<example xml:id="examp-basis-null-space">
  <statement>
    <p>
      Consider the following matrix <m>A \in M_{3,5}(\rr)</m>: 
      <me>
        A = \begin{bmatrix} 
        3 \amp -2 \amp -4 \amp -4 \amp 3 \\ 
        1 \amp -2 \amp 1 \amp 1 \amp 2 \\ 
        0 \amp 0 \amp 4 \amp 0 \amp -4
        \end{bmatrix}
      </me>. 
      We will find a basis for <m>\nll(A)</m>. 
    </p>
    <p>
      Following the procedure we first encountered in <xref ref="examp-find-null-space"/>, we start by finding the RREF of <m>A</m>:
      <me>
        A \sim \begin{bmatrix}
        1 \amp 0 \amp 0 \amp -5/2 \amp -2 \\ 
        0 \amp 1 \amp 0 \amp -7/4 \amp -5/2 \\ 
        0 \amp 0 \amp 1 \amp 0 \amp -1
        \end{bmatrix}
      </me>. 
      We see that <m>x_4</m> and <m>x_5</m> are free variables, and that any vector <m>\bfx</m> in <m>\nll(A)</m> can be written as 
      <me>
        \bfx = \begin{bmatrix}
        x_1 \\ x_2 \\ x_3 \\ x_4 \\ x_5 
        \end{bmatrix} = 
        \begin{bmatrix}
        (5/2)x_4 + 2x_5 \\ (7/4)x_4 + (5/2)x_5 \\ x_5 \\ x_4 \\ x_5 
        \end{bmatrix} = 
        x_4 \begin{bmatrix} 
        5/2 \\ 7/4 \\ 0 \\ 1 \\ 0 
        \end{bmatrix} + x_5 \begin{bmatrix} 
        2 \\ 5/2 \\ 1 \\ 0 \\ 1 
        \end{bmatrix}
      </me>. 
      If we label the vectors 
      <me>
        \bfv_1 = \begin{bmatrix} 
        5/2 \\ 7/4 \\ 0 \\ 1 \\ 0 
        \end{bmatrix} \hspace{6pt} \text{and} \hspace{6pt}
        \bfv_2 = \begin{bmatrix} 
        2 \\ 5/2 \\ 1 \\ 0 \\ 1 
        \end{bmatrix}
      </me>, 
      then we can see that <m>\nll(A) = \spn\{\bfv_1, \bfv_2 \}</m>. Further, we see that <m>\{\bfv_1, \bfv_2 \}</m> is linearly independent (neither vector is a scalar multiple of the other), so <m>\{ \bfv_1, \bfv_2 \}</m> is a basis for <m>\nll(A)</m>. 
    </p>
  </statement>
</example>

<note>
  <p>
    What we observed in <xref ref="examp-basis-null-space"/> is true more generally. Since the method we use to find a spanning set for <m>\nll(A)</m> always produces a linearly independent set (see <xref ref="exer-null-lin-ind"/>), this method will always produce a basis for <m>\nll(A)</m>. 
  </p>
</note>

<p>
  Here is an example where we are looking at whether a set of two vectors is a basis.
</p>

<example>
  <statement>
    <p>
      It turns out that it is fairly easy to tell whether a set of two vectors in <m>\rr^2</m> forms a basis for <m>\rr^2</m>. Since linear independence is easy to check with two vectors<mdash></mdash>is either vector a scalar multiple of the other?<mdash></mdash>we can focus on this characteristic. This means that the set <m>\{\bfv_1, \bfv_2 \}</m>, where 
      <me>
        \bfv_1 = \begin{bmatrix} 1 \\ -3 \end{bmatrix} \hspace{6pt} \text{and} \hspace{6pt}
        \bfv_2 = \begin{bmatrix} -2 \\ 5 \end{bmatrix}
      </me>
      is a basis for <m>\rr^2</m>. Neither vector is a scalar multiple of the other, so the set is linearly independent. And then <xref ref="cor-n-vect-in-f-n"/> tells us that this set must also span <m>\rr^2</m>. (We could also easily see this by row reducing the matrix <m>[\bfv_1\; \bfv_2]</m>.)      
    </p>
    <p>
      On the other hand, the set <m>W' = \{ \bfw_1, \bfw_2 \}</m>, where 
      <me>
        \bfw_1 = \begin{bmatrix} 2 \\ -1 \end{bmatrix} \hspace{6pt} \text{and} \hspace{6pt}
        \bfw_2 = \begin{bmatrix} -4 \\ 2 \end{bmatrix}
      </me>
      is not a basis for <m>\rr^2</m>. Since <m>\bfw_2 = -2\bfw_1</m>, <m>W'</m> is not linearly independent, so it cannot be a basis.
    </p>
  </statement>
</example>

<p>
  Putting some facts together, there is a fairly straightforward condition for when a set of vectors in <m>\ff^n</m> is a basis for that space.
</p>
  
<proposition xml:id="prop-basis-of-fn">
  <statement>
    <p>
      The set <m>\{\bfv_1, \ldots, \bfv_m \}</m> is a basis for <m>\ff^n</m> if and only if the RREF of the matrix <m>[\bfv_1 \cdots \bfv_m]</m> is <m>I_n</m>. 
    </p>
  </statement>
  <proof>
    <p>
      From <xref ref="thm-vectors-span-fm"/> we know that the set <m>V' = \{\bfv_1, \ldots, \bfv_m \}</m> spans <m>\ff^m</m> if and only if the RREF of <m>A=[\bfv_1 \cdots \bfv_m]</m> has a pivot in every row. Additionally, <xref ref="alg-linear-independence"/> tells us that <m>V'</m> is linearly independent if and only if the RREF of <m>A</m> has a pivot in each column. The only way a matrix in RREF can have a pivot in every row and every column is if that RREF is the identity matrix. 
    </p>
  </proof>
</proposition>

<p>
  We put this proposition into action in the following example.
</p>

<example>
  <statement>
    <p>
      Let <m>A \in M_3(\ff_5)</m> be the following matrix:
      <me>
        A = \begin{bmatrix} 3 \amp 4 \amp 4 \\
        3 \amp 0 \amp 1 \\
        4 \amp 3 \amp 4 \end{bmatrix}
      </me>.
      We will label column <m>i</m> in <m>A</m> as the vector <m>\bfv_i \in \ff_5^3</m>.
    </p>
    <p>
      Since the RREF of <m>A</m> is 
      <me>
        \begin{bmatrix} 1 \amp 0 \amp 2 \\
        0 \amp 1 \amp 2 \\
        0 \amp 0 \amp 0 \end{bmatrix}
      </me>,
      the set <m>\{\bfv_1,\bfv_2,\bfv_3\}</m> is not a basis for <m>\ff_5^3</m>.
    </p>
    <p>
      On the other hand, if <m>B \in M_3(\ff_5)</m> is the matrix
      <me>
        B = \begin{bmatrix} 1 \amp 1 \amp 0 \\
        1 \amp 2 \amp 3 \\
        0 \amp 3 \amp 0 \end{bmatrix}
      </me>,
      then the columns of <m>B</m> form a basis for <m>\ff_5^3</m> since the RREF of <m>B</m> is <m>I_3</m>.
    </p>
  </statement>
</example>

</subsection>

<subsection xml:id="subsec-basis-props">
  <title>The Properties of a Basis</title>
  
  <p>
    Having a basis is a powerful tool. In particular, it guarantees a uniqueness that is quite useful. 
  </p>

  <theorem xml:id="thm-unique-rep">
    <title>The Unique Representation Theorem</title>
    <statement>
      <p>
        A set of vectors <m>V' = \{\bfv_1, \ldots, \bfv_n \}</m> in a vector space <m>V</m> is a basis for <m>V</m> if and only if each element of <m>V</m> can be uniquely represented as a linear combination of the vectors in <m>V'</m>.
      </p>
    </statement>
    <proof>
      <p>
        We will prove the forward direction of this biconditional statement directly. Suppose that <m>V' = \{\bfv_1, \ldots, \bfv_n \}</m> is a basis of <m>V</m>. Since <m>V = \spn(V')</m>, every vector in <m>V</m> can be written as a linear combination of the vectors in <m>V'</m>. Let <m>\bfv</m> be a vector in <m>V</m>, and suppose that <m>\bfv</m> can be written as a linear combination of the vectors in <m>V'</m> in two ways: 
        <me>
          \bfv  = \sum_{i=1}^n a_i\bfv_i \hspace{6pt} \text{and} \hspace{6pt} \bfv = \sum_{i=1}^n b_i\bfv_i 
        </me>.
        We want to show that <m>a_i = b_i</m> for each <m>i</m>, <m>1 \le i \le n</m>. Since both of these representations are equal to <m>\bfv</m>, they are equal to each other, so we have 
        <me>
          \bfo = \sum_{i=1}^n a_i\bfv_i - \sum_{i=1}^n b_i\bfv_i = \sum_{i=1}^n (a_i-b_i)\bfv_i
        </me>. 
        Since <m>V'</m> is a linearly independent set (since we are assuming it is a basis), it must be that <m>a_i-b_i=0</m> for each <m>i</m>. Therefore, <m>a_i=b_i</m> and the representation of <m>\bfv</m> is unique. 
      </p>
      <p>
        For the other direction, we suppose that every element of <m>V</m> can be uniquely represented as a linear combination of the vectors in <m>V'</m>. Since every element of <m>V</m> can be represented as a linear combination of the vectors in <m>V'</m>, we see that <m>V'</m> spans <m>V</m>. Since every element in <m>V</m> can be represented <em>uniquely</em> as a linear combination of the vectors in <m>V'</m>, and since <m>\bfo \in V</m> can be represented as the trivial linear combination of the vectors in <m>V'</m>, this means that <m>V'</m> is linearly independent. (The trivial linear combination of vectors in <m>V'</m> is the <em>only</em> way to obtain <m>\bfo</m> as a linear combination of the vectors in <m>V'</m>.) Since <m>V'</m> is linearly independent and spans <m>V</m>, this proves that <m>V'</m> is a basis for <m>V</m>. 
      </p>
    </proof>
  </theorem>

  <p>
    This next result shows us how to trim a spanning set down until we reach a basis. 
  </p>

  <theorem xml:id="thm-spanning-set">
    <title>The Spanning Set Theorem</title>    
    <statement>
      <p>
        Suppose that <m>V</m> is a nonzero, finite-dimensional vector space and that <m>V = \spn(B)</m> for some set of vectors <m>B\subseteq V</m>. 
        <ol>
          <li>
            <p>
              If <m>B</m> is a linearly dependent set and a vector <m>\bfw \in B</m> can be written as a linear combination of the rest of the vectors in <m>B</m>, then <m>{\spn(B) = \spn(B - \{\bfw \})}</m>. 
            </p>
          </li>
          <li>
            <p>
              A subset of <m>B</m> is a basis for <m>V</m>. 
            </p>
          </li>
        </ol>       
      </p>
    </statement>
    <proof>
      <p>
        We suppose that <m>B = \{\bfv_1, \ldots, \bfv_n \}</m>. If <m>B</m> is linearly dependent, then by the Linear Dependence Lemma (<xref ref="thm-lin-dep-lemma"/>), there exists a vector <m>\bfv_k \in B</m> such that <m>\bfv_k</m> can be written as a linear combination of the vectors <m>\bfv_1, \ldots, \bfv_{k-1}</m>. We suppose this combination is 
        <men xml:id="eqn-rep-vk">
          \bfv_k = a_1\bfv_1 + \cdots + a_{k-1}\bfv_{k-1}
        </men>. 
        Now suppose <m>\bfv</m> is a vector in <m>V</m>. We have 
        <men xml:id="eqn-rep-v">
          \bfv = c_1 \bfv_1 + \cdots + c_{k-1}\bfv_{k-1} + c_k\bfv_k + c_{k+1}\bfv_{k+1} + \cdots + c_n \bfv_n
        </men>. 
        Using <xref ref="eqn-rep-vk"/>, we can substitute this expression in for <m>\bfv_k</m> in <xref ref="eqn-rep-v"/> and, once the algebraic dust settles, we will have written <m>\bfv</m> as a combination of the vectors in <m>B - \{\bfv_k\}</m>. This shows that <m>\spn(B) = \spn(B - \{\bfv_k\})</m>. (Since <m>B - \{\bfv_k\} \subseteq B</m>, it is true that <m>\spn(B - \{\bfv_k\}) \subseteq \spn(B)</m>. The argument thus far in this proof has established the other subset containment.)
      </p>
      <p>
        If <m>B</m> is  linearly independent, then it is already a basis for <m>V</m>. If it is linearly dependent, then we can remove a vector according to the above procedure to obtain a set <m>B_1 = B - \{\bfw\}</m> which still spans <m>V</m>. As long as there are two or more vectors in the spanning set, we can repeat this process until we are left with a linearly independent set and thus a basis. If the spanning set is eventually reduced to a single vector, that vector will be nonzero since <m>V</m> is nonzero, and therefore that set will be linearly independent and therefore a basis.
      </p>
    </proof>
  </theorem>

    <corollary xml:id="cor-basis-fin-dim">
    <statement>
      <p>
        Every finite-dimensional vector space has a basis. 
      </p>
    </statement>
    <proof>
      <p>
        Since a finite-dimensional vector space by definition has a finite spanning set <m>B</m>, <xref ref="thm-spanning-set"/> tells us that a subset of <m>B</m> will be a basis for the vector space.
      </p>
    </proof>
  </corollary>

  <p>
    While the proof of <xref ref="thm-spanning-set"/> provides a way to trim a spanning set down to a basis, it does not offer a practical method for this process. The following algorithm provides such a method for certain vector spaces.
  </p>

  <algorithm xml:id="alg-find-basis">
    <statement>
      <p>
        Let <m>V' = \{\bfv_1, \ldots, \bfv_n\}</m> be a set of vectors in <m>\ff^m</m>. The following steps result in a basis <m>B</m> for <m>\spn(V')</m>. 
        <ol>
          <li>
            <p>
              Put the matrix <m>A = [\bfv_1 \cdots \bfv_n ]</m> in RREF.           
            </p>
          </li>
          <li>
            <p>
              If column <m>i</m> in the RREF contains a pivot, then include <m>\bfv_i</m> in <m>B</m>. 
            </p>
          </li>
        </ol>
      </p>
    </statement>
    <proof>
      <p>
        We form the matrix <m>A = [\bfv_1 \cdots \bfv_n]</m>. If <m>A</m> is already in RREF, then the non-pivot columns are linear combinations of the pivot columns that preceed them (when reading from left to right). So, those can be discarded and the pivot columns will be a basis, according to <xref ref="thm-spanning-set"/>. 
      </p>
      <p>
        We will complete the proof with a reminder about the effect of elementary row operations on the columns of a matrix. If a column <m>\bfv_k</m> of <m>A</m> is a linear combination of the columns that preceed it, then 
        <me>
          \bfv_k = \sum_{i=1}^{k-1} c_i\bfv_i 
        </me>
        for some scalars <m>c_i</m>. This means that the column vector <m>[c_i]</m> is a solution to the linear system represented by the augmented matrix <m>[\bfv_1 \cdots \bfv_{k-1} \mid \bfv_k ]</m>. One of the earliest facts we learned about elementary row operations is that they preserve the solution sets of linear systems, so the same vector <m>[c_i]</m> will be a solution to the linear system represented by the RREF of <m>[\bfv_1 \cdots \bfv_{k-1} \mid \bfv_k ]</m>. This proves that the relationships between the columns of a matrix are the same as the relationships between the columns of the RREF of that matrix. 
      </p>
      <p>
        So, if <m>A</m> is not in RREF, we can find the RREF of <m>A</m>, call it <m>C</m>. The non-pivot columns of <m>C</m> indicate that the corresponding columns of <m>A</m> should not be included in the basis. In other words the pivot columns of <m>C</m> indicate that the corresponding columns of <m>A</m> are the ones that should remain to form the basis. 
      </p>
    </proof>
  </algorithm>

  <note>
    <p>
      We emphasize here that the pivot columns in the reduced matrix do not provide the vectors for the basis! The pivot columns merely provide the <em>instructions</em> for which of the original vectors should be kept to form the basis.
    </p>
  </note>

  <example xml:id="examp-colA-basis">
    <statement>
      <p>
        Consider the following matrix <m>A \in M_{4,5}(\ff_5)</m>: 
        <me>
          A = \begin{bmatrix}
          3 \amp 2 \amp 3 \amp 3 \amp 3 \\ 
          0 \amp 0 \amp 1 \amp 4 \amp 0 \\ 
          3 \amp 2 \amp 0 \amp 1 \amp 2 \\ 
          0 \amp 0 \amp 2 \amp 3 \amp 1
          \end{bmatrix}
        </me>. 
        We will find a basis for <m>\col(A)</m> using <xref ref="alg-find-basis"/>. When we put <m>A</m> into RREF, we find 
        <me>
          A \sim \begin{bmatrix}
          1 \amp 4 \amp 0 \amp 2 \amp 0 \\ 
          0 \amp 0 \amp 1 \amp 4 \amp 0 \\ 
          0 \amp 0 \amp 0 \amp 0 \amp 1 \\ 
          0 \amp 0 \amp 0 \amp 0 \amp 0
          \end{bmatrix}
        </me>. 
        The pivots are in columns 1, 3, and 5, so a basis for <m>\col(A)</m> is <m>\{ \bfv_1, \bfv_3, \bfv_5 \}</m>, where 
          <me>
            \bfv_1 = \begin{bmatrix} 3 \\ 0 \\ 3 \\ 0 \end{bmatrix}, \hspace{6pt} 
            \bfv_3 = \begin{bmatrix} 3 \\ 1 \\ 0 \\ 2 \end{bmatrix}, \hspace{6pt} 
            \bfv_5 = \begin{bmatrix} 3 \\ 0 \\ 2 \\ 1 \end{bmatrix}, \hspace{6pt} 
          </me>.           
      </p>
    </statement>
  </example>
  

  <p>
    We arrive at the end of this section with two helpful perspectives on a basis. A basis can be formed by trimming a spanning set down until it is linearly independent. Thus, a basis is a spanning set that is as small as possible. On the other hand, a linearly independent set can always be enlarged until it spans. Therefore, a basis is also a linearly independent set that is as large as possible. 
  </p>
  
</subsection>

<reading-questions>
  <exercise>
  <statement>
    <p>
      Consider the set <m>V' = \{\bfv_1, \bfv_2, \bfv_3, \bfv_4\}</m> in <m>\rr^3</m> where 
      <me>
        \bfv_1 = \begin{bmatrix} 
        -3 \\ 1 \\ 4 
        \end{bmatrix}, \hspace{6pt}
        \bfv_2 = \begin{bmatrix} 
        6 \\ 2 \\ 1 
        \end{bmatrix}, \hspace{6pt}
        \bfv_3 = \begin{bmatrix} 
        0 \\ 4 \\ -1  
        \end{bmatrix}, \hspace{6pt}
        \bfv_4 = \begin{bmatrix} 
        2 \\ -2 \\ 7
        \end{bmatrix}
      </me>. 
      Find a basis for <m>\spn(V')</m>. Follow <xref ref="examp-colA-basis"/> and explain your answer.
    </p>
    <!-- <p>
      A basis is <m>\{\bfv_1, \bfv_2, \bfv_3\}</m>, since <m>\begin{bmatrix} \bfv_1 \amp \bfv_2 \amp \bfv_3 \amp \bfv_4 \end{bmatrix} \sim \begin{bmatrix} 1 \amp 0 \amp 0 \amp \frac{6}{5} \\ 
      0 \amp 1 \amp 0 \amp \frac{14}{15} \\ 
      0 \amp 0 \amp 1 \amp -\frac{19}{15} \end{bmatrix} </m>
    </p> -->
  </statement>
</exercise>
<exercise> 
<statement>
  <p>
    Determine whether or not the set <m>\{ \bfv_1, \bfv_2, \bfv_3 \}</m> forms a basis for <m>\ff_7^3</m>, where 
    <me>
      \bfv_1 = \begin{bmatrix} 
        4 \\ 1 \\ 0 
        \end{bmatrix}, \hspace{6pt}
        \bfv_2 = \begin{bmatrix} 
        5 \\ 0 \\ 0 
        \end{bmatrix}, \hspace{6pt}
        \bfv_3 = \begin{bmatrix} 
        5 \\ 6 \\ 2  
        \end{bmatrix}
    </me>.    
    Explain your answer.
  </p>
  <!-- <p>
    Yes, since <m>\begin{bmatrix} \bfv_1 \amp \bfv_2 \amp \bfv_3 \end{bmatrix} \sim I_3</m>. 
  </p> -->
</statement>
</exercise>
</reading-questions>

<exercises>
  <exercise>
    <statement>
      <p>
        For each of the following, determine whether the given set of vectors forms a basis for the indicated vector space.
        <ol> 
          <li>
          <p>
            <m>\{\bfv_1, \bfv_2, \bfv_3\}</m> in <m>\rr^3</m> if 
            <me>
              \bfv_1 = \begin{bmatrix} 
              -2 \\ 0.5 \\ -1
              \end{bmatrix}, \hspace{6pt}
              \bfv_2 = \begin{bmatrix} 
              -4.5 \\ -2.5 \\ 4.5
              \end{bmatrix}, \hspace{6pt}
              \bfv_3 = \begin{bmatrix} 
              4.5 \\ 1.5 \\ -4.5
              \end{bmatrix}
            </me>            
          </p>
        </li>
        <li>
          <p>
            <m>\{\bfv_1, \bfv_2 \}</m> in <m>\ff_5^2</m> if 
            <me>
              \bfv_1 = \begin{bmatrix} 
              1 \\ 4
              \end{bmatrix}, \hspace{6pt}
              \bfv_2 = \begin{bmatrix} 
              3 \\ 2
              \end{bmatrix}
            </me>            
          </p>
        </li>
        <li>
          <p>
            <m>\{p_1, p_2, p_3\}</m> in <m>P_2</m> if 
            <me>
              p_1 = 4 + 2t + 4t^2, \hspace{6pt} p_2 = -3+4t, \hspace{6pt} p_3 = 2-2t-4t^2
            </me>            
          </p>
        </li>
      </ol>
      </p>
    </statement>
  </exercise>
  <exercise>
    <statement>
      <p>
        For each of the following, determine whether the given set of vectors forms a basis for the indicated vector space.
        <ol>
          <li>
            <p>
              <m>\{\bfv_1, \bfv_2, \bfv_3, \bfv_4\}</m> in <m>\rr^4</m> if 
              <me>
              \bfv_1 = \begin{bmatrix} 
              0 \\ -2 \\ 1 \\ -3
              \end{bmatrix}, \hspace{6pt}
              \bfv_2 = \begin{bmatrix} 
              -2 \\ 2 \\ 1 \\ -2
              \end{bmatrix}, \hspace{6pt}
              \bfv_3 = \begin{bmatrix} 
              -4 \\ -2 \\ 5 \\ -13
              \end{bmatrix}, \hspace{6pt}
              \bfv_4 = \begin{bmatrix} 
              3 \\ 0 \\ 1 \\ 0
              \end{bmatrix}
              </me>              
            </p>
          </li>
          <li>
            <p>
              <m>\{\bfv_1, \bfv_2, \bfv_3 \}</m> in <m>\ff_3^3</m> if 
              <me>
                \bfv_1 = \begin{bmatrix} 
                1 \\ 0 \\ 2
                \end{bmatrix}, \hspace{6pt}
                \bfv_2 = \begin{bmatrix} 
                1 \\ 1 \\ 0
                \end{bmatrix}, \hspace{6pt}
                \bfv_3 = \begin{bmatrix} 
                0 \\ 1 \\ 1
                \end{bmatrix} 
              </me>              
            </p>
          </li>
          <li>
            <p>
              <m>\{p_1, p_2, p_3 \}</m> in <m>P_2</m> if 
              <me>
                p_1 = 3+3t-4t^2, \hspace{6pt} p_2 = 3-3t, \hspace{6pt} p_3 = 12 + 6t -12t^2
              </me>              
            </p>
          </li>
        </ol>
      </p>
    </statement>
    <answer>
      <p>
        <ol>
          <li>
            <p>
              No.
            </p>
          </li>
          <li>
            <p>
              No.
            </p>
          </li>
          <li>
            <p>
              No.
            </p>
          </li>
        </ol>
      </p>
    </answer>
  </exercise>
  <exercise>
    <statement>
      <p>
        For each matrix <m>A</m>, find a basis for <m>\nll(A)</m> and <m>\col(A)</m>. 
        <ol>
          <li>
            <p>
              <m>A \in M_{3,4}(\rr)</m>, 
              <me>
                A = \begin{bmatrix} 
                -3 \amp 2 \amp -2 \amp 0.5 \\ 
                2.5 \amp 5 \amp 15 \amp 5 \\ 
                -5 \amp -1.5 \amp -13 \amp 0.5
                \end{bmatrix}
              </me>              
            </p>
          </li>
          <li>
            <p>
              <m>A \in M_{4,6}(\ff_5)</m>,
              <me>
                A = \begin{bmatrix} 
                3 \amp 2 \amp 0 \amp 4 \amp 3 \amp 4 \\ 
                3 \amp 3 \amp 3 \amp 1 \amp 3 \amp 1 \\ 
                4 \amp 0 \amp 2 \amp 0 \amp 3 \amp 3 \\ 
                4 \amp 4 \amp 1 \amp 2 \amp 0 \amp 2
                \end{bmatrix}
              </me>              
            </p>
          </li>
        </ol>
      </p>
    </statement>
  </exercise>
  <exercise>
    <statement>
      <p>
        Produce a matrix <m>A \in M_{3,4}(\ff_5)</m> which has two vectors in a basis for <m>\nll(A)</m> and two vectors in a basis for <m>\col(A)</m>. 
      </p>
    </statement>
    <answer>
      <p>
        Any matrix that has two pivot columns and two non-pivot columns will work as an answer here. This is one of many such matrices:
        <me>
          \begin{bmatrix} 1 \amp 2 \amp 0 \amp 3 \\ 0 \amp 0 \amp 1 \amp 3 \\ 0 \amp 0 \amp 0 \amp 0 \end{bmatrix}
        </me>.
        Of course, any matrix row equivalent to a matrix like this one would also work as an answer.
      </p>
    </answer>
  </exercise>
  <exercise>
    <statement>
      <p>
        Find a basis for <m>\spn\{\bfv_1, \bfv_2, \bfv_3, \bfv_4, \bfv_5 \} \subseteq \rr^4</m>, if 
        <me>
          \bfv_1 = \begin{bmatrix} 
          -2 \\ -3 \\ -2 \\ 1
          \end{bmatrix}, \hspace{6pt}
          \bfv_2 = \begin{bmatrix} 
          -2 \\ 0 \\ -1 \\ -1
          \end{bmatrix}, \hspace{6pt}
          \bfv_3 = \begin{bmatrix} 
          2 \\ 9 \\ 10 \\ 1
          \end{bmatrix}, \hspace{6pt}
          \bfv_4 = \begin{bmatrix} 
          3 \\ 2 \\ -4 \\ 9
          \end{bmatrix}, \hspace{6pt}
          \bfv_5 = \begin{bmatrix} 
          12 \\ -16 \\ 5 \\ 1
          \end{bmatrix}
        </me>.        
      </p>
    </statement>
  </exercise>
  <exercise>
    <statement>
      <p>
        Find a basis for <m>\spn\{\bfv_1, \bfv_2, \bfv_3, \bfv_4, \bfv_5 \} \subseteq \ff_5^4</m>, if 
        <me>
          \bfv_1 = \begin{bmatrix} 
          0 \\ 0 \\ 2 \\ 3
          \end{bmatrix}, \hspace{6pt}
          \bfv_2 = \begin{bmatrix} 
          3 \\ 1 \\ 3 \\ 0
          \end{bmatrix}, \hspace{6pt}
          \bfv_3 = \begin{bmatrix} 
          2 \\ 0 \\ 0 \\ 2
          \end{bmatrix}, \hspace{6pt}
          \bfv_4 = \begin{bmatrix} 
          1 \\ 2 \\ 4 \\ 2
          \end{bmatrix}, \hspace{6pt}
          \bfv_5 = \begin{bmatrix} 
          1 \\ 4 \\ 3 \\ 3
          \end{bmatrix}
        </me>.  
      </p>
    </statement>
    <answer>
      <p>
        A basis is <m>\{\bfv_1, \bfv_2, \bfv_3 \}</m>.
      </p>
    </answer>
  </exercise>
  <exercise>
    <statement>
      <p>
        Let <m>V</m> be the vector space of all functions <m>\rr \to \rr</m>. Find a basis for the subspace <m>H</m>, if 
        <me>
          H = \spn\{\sin(t), \sin(2t), \sin(t)\cos(t) \}
        </me>.        
      </p>
    </statement>
    <answer>
      <p>
        We will argue using the (contrapositive of the) Linear Dependence Lemma. Since <m>\sin(t)</m> is not the zero function, then <m>\{\sin(t)\}</m> is a linearly independent set. Also, since <m>\sin(2t)</m> is not a scalar multiple of <m>\sin(t)</m> (this can be verified by comparing graphs of the two functions), the set <m>\{\sin(t), \sin(2t)\}</m> is also linearly independent. However, there is a trig identity which says that <m>\sin(2t) = 2\sin(t)\cos(t)</m>, meaning that the set <m>\{\sin(t), \sin(2t), \sin(t)\cos(t) \}</m> is linearly dependent (as one vector is a multiple of another within this set). Therefore, one basis for <m>H</m> is <m>\{\sin(t), \sin(2t)\}</m>. 
      </p>
    </answer>
  </exercise>
  <exercise>
    <statement>
      <p>
        Find a matrix <m>A \in M_2(\rr)</m> such that 
        <me>
          A \begin{bmatrix} 1 \\ 3 \end{bmatrix} = \begin{bmatrix} 2 \\ 0 \end{bmatrix}, \hspace{6pt} 
          A \begin{bmatrix} -1 \\ -2 \end{bmatrix} = \begin{bmatrix} 1 \\ 1 \end{bmatrix}
        </me>. 
        Is <m>A</m> unique? Explain.
      </p> <!-- -7 & 3 \\ -3 & 1, unique -->
    </statement>
  </exercise>
  <exercise>
    <statement>
      <p>
        Suppose that <m>T:\rr^3 \to \rr^2</m> is a linear transformation which satisfies the following: 
        <me>
          T \left( \begin{bmatrix} 1 \\ 1 \\ 3 \end{bmatrix}  \right) = \begin{bmatrix} 2 \\ -1 \end{bmatrix}, \hspace{6pt}
          T \left( \begin{bmatrix} -1 \\ 0 \\ 2 \end{bmatrix}  \right) = \begin{bmatrix} 1 \\ 0 \end{bmatrix}, \hspace{6pt}
          T \left( \begin{bmatrix} 3 \\ -2 \\ 0 \end{bmatrix}  \right) = \begin{bmatrix} 3 \\ -2 \end{bmatrix}
        </me>. 
        Calculate 
        <me>
          T \left( \begin{bmatrix} -1 \\ 4 \\ 6 \end{bmatrix}  \right)
        </me>.         
      </p>
    </statement>
  </exercise>
  <exercise>
    <statement>
      <p>
        Find a subset of the following set which is a basis for <m>P_2</m>:
        <me>
          \{t-1, t^2-2t, t^2-2, t^2+1 \}
        </me>.         
      </p>
    </statement>
  </exercise>
  <subexercises>
    <title>Writing Exercises</title>   
    <exercise>
      <statement>
        <p>
          Let <m>T: V\to W</m> be a linear transformation between vector spaces, and let <m>B</m> be a basis for <m>V</m>. 
          <ol>
            <li>
              <p>
                Produce an example to show that <m>T(B)</m> does not need to be a basis of <m>W</m>. 
              </p>
            </li>
            <li>
              <p>
                Suppose that <m>T</m> is injective. Must <m>T(B)</m> be a basis for <m>W</m>? If so, prove it. If not, produce a counter-example. 
              </p>
            </li>
            <li>
              <p>
                Suppose that <m>T</m> is surjective. Must <m>T(B)</m> be a basis for <m>W</m>? If so, prove it. If not, produce a counter-example. 
              </p>
            </li>
          </ol>
        </p>
      </statement>
    </exercise>   
    <exercise>
      <statement>
        <p>
          Suppose that <m>\{\bfv_1, \ldots, \bfv_n \}</m> is a basis for a vector space <m>V</m>. Prove that 
          <me>
            \{ \bfv_1 + \bfv_2, \bfv_2 + \bfv_3, \ldots, \bfv_{n-1} + \bfv_n, \bfv_n \}
          </me>
          is also a basis for <m>V</m>. 
        </p>
      </statement>
      <solution>
        <p>
          We let <m>B = \{ \bfv_1 + \bfv_2, \bfv_2 + \bfv_3, \ldots, \bfv_{n-1} + \bfv_n, \bfv_n \}</m>. We will first show that <m>B</m> is linearly independent.
        </p>
        <p>
          We first suppose that <m>c_1, \ldots, c_n</m> are scalars such that
          <me>
            c_1(\bfv_1 + \bfv_2) + \cdots + c_{n-1}(\bfv_{n-1} + \bfv_n) + c_n\bfv_n = \bfo
          </me>.
          Rearranging this equation, we see that it is equivalent to 
          <me>
            c_1\bfv_1 + (c_1+c_2)\bfv_2 + \cdots + (c_{n-1} + c_n)\bfv_n = \bfo
          </me>.
          However, since we were given that <m>B' = \{\bfv_1, \ldots, \bfv_n \}</m> is a basis for <m>V</m>, this means that the coefficients in this last equation must all be zero, since <m>B'</m> is linearly independent. This means that <m>c_1 = 0</m>, and then since we must also have <m>c_1+c_2 = 0</m>, we have <m>c_2 = 0</m>, and so on. The result is that <m>c_i = 0</m> for all <m>i</m>, <m>i=1,\ldots,n</m>. This proves that <m>B</m> is linearly independent.
        </p>
        <p>
          We will now show that <m>B</m> spans <m>V</m>. Let <m>\bfv \in V</m>. We want to argue that <m>\bfv</m> can be written as a linear combination of the vectors in <m>B</m>. Since <m>B'</m> is a basis for <m>V</m>, there exist scalars <m>d_1,\ldots, d_n</m> such that 
          <men xml:id="d-coeffs">
            \bfv = d_1\bfv_1 + \cdots + d_n\bfv_n
          </men>.
          We want to argue that we can always find scalars <m>c_1, \ldots, c_n</m> such that 
          <me>
            \bfv = c_1(\bfv_1 + \bfv_2) + \cdots + c_n\bfv_n
          </me>.
          This equation can be rewritten as 
          <men xml:id="c-coeffs">
            \bfv = c_1\bfv_1 + (c_1+c_2)\bfv_2 + \cdots + (c_{n-1}+c_n)\bfv_n
          </men>,
          and by The Unique Representation Theorem (<xref ref="thm-unique-rep"/>), we know that the coefficients on the right sides of <xref ref="d-coeffs"/> and <xref ref="c-coeffs"/> must be equal. Immediately we see that <m>c_1 = d_1</m> and then since we must have <m>c_1 + c_2 = d_2</m>, we conclude <m>c_2 = d_2 - d_1</m>. We can continue on in this way, eventually producing an expression for each <m>c_i</m> in terms of the <m>d_i</m> coefficients.  
        </p>
        <p>
          This proves that <m>B</m> spans <m>V</m> which concludes the proof that <m>B</m> is a basis of <m>V</m>.
        </p>
      </solution>
    </exercise>
    <exercise>
      <statement>
        <p>
          Prove or disprove: Every basis of <m>P_2</m> must contain a polynomial of degree 2, a polynomial of degree 1, and a constant polynomial.
        </p>
      </statement>
    </exercise>
    <exercise>
      <statement>
        <p>
          Write down a basis for <m>M_2(\rr)</m>. Prove that your set is a basis. (There is no need to prove that <m>M_2(\rr)</m> is a vector space as this was covered in <xref ref="matrices-vspace"/>.)
        </p>
      </statement>
    </exercise>
  </subexercises>
</exercises> 


</section>