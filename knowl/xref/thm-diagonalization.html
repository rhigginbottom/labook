<!DOCTYPE html>
<html lang="en-US" dir="ltr">
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="robots" content="noindex, nofollow">
</head>
<body class="ignore-math">
<article class="theorem theorem-like"><h4 class="heading">
<span class="type">Theorem</span><span xmlns:xlink="http://www.w3.org/1999/xlink" class="space"> </span><span class="codenumber">6.3.2</span><span xmlns:xlink="http://www.w3.org/1999/xlink" class="period">.</span><span xmlns:xlink="http://www.w3.org/1999/xlink" class="space"> </span><span class="title">The Diagonalization Theorem.</span>
</h4>
<div xmlns:xlink="http://www.w3.org/1999/xlink" class="para">A matrix <span class="process-math">\(A \in M_n(\ff)\)</span> is diagonalizable if and only if <span class="process-math">\(A\)</span> has <span class="process-math">\(n\)</span> linearly independent eigenvectors.</div> <div xmlns:xlink="http://www.w3.org/1999/xlink" class="para">More specifically, <span class="process-math">\(A = PDP^{-1}\text{,}\)</span> for a diagonal matrix <span class="process-math">\(D\text{,}\)</span> if and only if the columns of <span class="process-math">\(P\)</span> are <span class="process-math">\(n\)</span> linearly independent eigenvectors of <span class="process-math">\(A\text{.}\)</span> In this case, the diagonal entries of <span class="process-math">\(D\)</span> are the the eigenvalues of <span class="process-math">\(A\)</span> which correspond, respectively, to the columns of <span class="process-math">\(P\text{.}\)</span>
</div></article><details xmlns:xlink="http://www.w3.org/1999/xlink" class="hiddenproof born-hidden-knowl"><summary class="knowl__link"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4></summary><article class="hiddenproof knowl__content"><div class="para logical">
<div class="para">If <span class="process-math">\(P\)</span> is an <span class="process-math">\(n\times n\)</span> matrix with columns <span class="process-math">\(\bfv_1, \ldots, \bfv_n\text{,}\)</span> and if <span class="process-math">\(D\)</span> is a diagonal matrix with diagonal entries <span class="process-math">\(\lambda_1, \ldots, \lambda_n\text{,}\)</span> then we have</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/xref/eqn-diag-thm-2.html ./knowl/xref/eqn-diag-thm-1.html ./knowl/xref/eqn-diag-thm-2.html">
\begin{equation}
AP = A \begin{bmatrix} \bfv_1 \amp \cdots \amp \bfv_n \end{bmatrix} = \begin{bmatrix} A\bfv_1 \amp \cdots \amp A\bfv_n \end{bmatrix}\text{,}\tag{6.4}
\end{equation}
</div>
<div class="para">and also</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/xref/eqn-diag-thm-2.html ./knowl/xref/eqn-diag-thm-1.html ./knowl/xref/eqn-diag-thm-2.html">
\begin{equation}
PD = \begin{bmatrix} \lambda_1\bfv_1 \amp \cdots \amp \lambda_n\bfv_n \end{bmatrix}\text{.}\tag{6.5}
\end{equation}
</div>
<div class="para">(If the reader has trouble believing <a href="sec-diagonalization.html#eqn-diag-thm-2" class="xref" data-knowl="./knowl/xref/eqn-diag-thm-2.html" data-reveal-label="Reveal" data-close-label="Close" title="Equation 6.5">(6.5)</a>, thinking of matrix multiplication, in each column of the product, as a linear combination of the columns of <span class="process-math">\(P\)</span> with weights coming from the corresponding column of <span class="process-math">\(D\text{,}\)</span> may help!) If <span class="process-math">\(A\)</span> is diagonalizable, then <span class="process-math">\(A = PDP^{-1}\)</span> and <span class="process-math">\(AP = PD\text{.}\)</span> From <a href="sec-diagonalization.html#eqn-diag-thm-1" class="xref" data-knowl="./knowl/xref/eqn-diag-thm-1.html" data-reveal-label="Reveal" data-close-label="Close" title="Equation 6.4">(6.4)</a> and <a href="sec-diagonalization.html#eqn-diag-thm-2" class="xref" data-knowl="./knowl/xref/eqn-diag-thm-2.html" data-reveal-label="Reveal" data-close-label="Close" title="Equation 6.5">(6.5)</a>, by equating columns in <span class="process-math">\(AP\)</span> and <span class="process-math">\(PD\)</span> we see that <span class="process-math">\(A\bfv_i = \lambda_i\bfv_i\)</span> for <span class="process-math">\(1 \le i \le n\text{.}\)</span> Since <span class="process-math">\(P\)</span> is invertible, the columns of <span class="process-math">\(P\)</span> must be linearly independent. Further, since the columns of <span class="process-math">\(P\)</span> cannot be zero vectors, this argument shows that <span class="process-math">\(\lambda_i\)</span> is an eigenvalue of <span class="process-math">\(A\)</span> with eigenvector <span class="process-math">\(\bfv_i\text{,}\)</span> for each <span class="process-math">\(i\text{.}\)</span> This proves one direction of the theorem.</div>
</div>
<div class="para">If we are given <span class="process-math">\(\bfv_1, \ldots, \bfv_n\)</span> as eigenvectors of <span class="process-math">\(A\)</span> with corresponding eigenvalues <span class="process-math">\(\lambda_1, \ldots, \lambda_n\text{,}\)</span> then we can form the matrices <span class="process-math">\(P\)</span> and <span class="process-math">\(D\text{.}\)</span> The argument in the previous paragraph shows that <span class="process-math">\(AP = PD\text{.}\)</span> (Note that we have not yet used the linear independence of the eigenvectors!) If the eigenvectors are linearly independent, then <span class="process-math">\(P\)</span> is invertible, and <span class="process-math">\(AP = PD\)</span> implies <span class="process-math">\(A = PDP^{-1}\text{,}\)</span> making <span class="process-math">\(A\)</span> diagonalizable.</div></article></details><span class="incontext"><a class="internal" href="sec-diagonalization.html#thm-diagonalization">in-context</a></span>
</body>
</html>
